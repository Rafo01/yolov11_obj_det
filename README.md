# yolov11_obj_det


 Доступ к данным и визуализациям
Для воспроизведения экспериментов и ознакомления с результатами обучения была создана структура папок.

ссылку на папку Google Drive, содержащую весь набор данных и визуализации.

https://drive.google.com/drive/folders/1raWNEklFJKiqo5GIiEZxbw0_KBbac2Uf?usp=sharing


### Извлечение кадров (Motion-Aware Frame Extraction)
Для извлечения кадров из видеоданных был реализован кастомный подход с учётом анализa движения и разнообразия сцен. Это позволило сформировать датасет из наиболее информативных и разнообразных изображений, улучшая качество обучения модели.

1) Алгоритм извлечения кадров включал следующие этапы:
   1.1 Поиск всех видеофайлов в указанной директории с возможностью рекурсивного поиска

2) Адаптивное определение интервала кадров на основе:
   2.1 Продолжительности видео
   2.2 Оценки движения на кадрах (порог движения motion_threshold)

3)Выбор кадров по нескольким критериям:
   3.1 Первый и последний кадр (гарантировано)
   3.2 Кадры с регулярным интервалом (например, каждые 30–45 кадров)
   3.3 Кадры со значительным изменением по сравнению с предыдущими (детектирование движения)

4) Техническая реализация:
   4.1 Для анализа движения используется разность между смягчёнными grayscale-кадрами (cv2.absdiff) и бинаризация изменений (cv2.threshold).
   4.2 Измеряется процент пикселей, изменившихся между двумя кадрами.
   4.3 Сохраняются кадры, в которых изменение превышает адаптивный порог.

5) Структура выходных данных:
   5.1 Кадры сохраняются в папке extracted_frames/

### Аннотирование изображений и подготовка данных для автолейблинга

Для аннотирования изображений использовался инструмент LabelImg, который позволяет вручную размечать bounding boxes и классы объектов на изображениях. В результате процесса извлечения было получено 680 изображений, из которых:

180 изображений были размечены вручную

Были созданы 8 классов объектов:
container
cup
tea
soup
meat
salad
dish
plate

Файлы аннотаций сохранялись в формате YOLO — для каждого изображения создавался текстовый .txt файл с координатами рамок и индексами классов.

### Подготовка данных для автолейблинга с помощью модели YOLOv8
После создания начального набора размеченных изображений, был реализован скрипт для подготовки датасета для автоматической доразметки с использованием модели YOLOv8.

Основные шаги:

1) Разделение изображений на размеченные и неразмеченные:
2) Изображения с соответствующими .txt файлами копируются в images/train
3) Остальные изображения — в images/unlabeled
4) Копирование разметок в labels/train
5) Создание файла классов classes.txt, содержащего список из 8 классов
6) Формирование data.yaml, необходимого для запуска обучения YOLOv8


Структура итогового датасета:

```markdown

yolov8/
├── images/
│   ├── train/        # размеченные изображения
│   └── unlabeled/    # изображения без аннотаций
├── labels/
│   └── train/        # YOLO .txt аннотации
├── classes.txt       # список классов
└── data.yaml         # конфигурация для YOLOv8

```

Создан тренировочный набор: images/train, labels/train

Подготовлены данные для последующего обучения и инференса YOLOv8 модели



### Автоматическая разметка изображений с помощью YOLOv8

После ручной аннотации части изображений и подготовки структуры датасета, была проведена автоматическая разметка (auto-labeling) оставшихся неразмеченных изображений с помощью модели YOLOv8.

#### Этапы автолейблинга:
1. Обучение YOLOv8 на вручную размеченных данных
Модель YOLOv8n была обучена на 180 вручную размеченных изображениях (из директории images/train и labels/train). Использовались следующие параметры обучения:

1) Модель: yolov8n.pt (наименьшая и самая быстрая версия YOLOv8)
2) Количество эпох: 2
3) Размер изображения: 640×640
4) Batch size: 16

####  Инференс на неразмеченных изображениях
После обучения была загружена полученная модель (best.pt) и применена ко всем изображениям из директории images/unlabeled с целью предсказания bounding boxes.

Параметры инференса:

1) Порог вероятности (confidence threshold): 0.3
2) Обработка пакетами (batch): по 10 изображений
3) Сохранение предсказаний в формате .txt 


####Итоговая структура автолейблинга:

```markdown
yolov8/
├── images/
│   ├── train/        # вручную размеченные изображения
│   └── unlabeled/    # изображения без ручной разметки
├── labels/
│   ├── train/        # ручные аннотации
│   └── unlabeled/    # аннотации, полученные автоматически
└── runs/
    ├── yolo_train/   # обучение модели
    └── autolabel/    # предсказания модели

```

#### Результаты после автоматической разметки

#### Общая информация о модели

1) Архитектура модели: YOLOv8n
2) Количество слоёв: 72
3) Параметров: 11,128,680
4) Объем операций (GFLOPs): 28.5
5) Количество обучающих изображений: 180
6) Общее число объектов (instances): 1128

#### Метрики качества на валидации:

| Метрика                  | Значение |
| ------------------------ | -------- |
| **Precision (точность)** | 0.923    |
| **Recall (полнота)**     | 0.799    |
| **mAP\@0.5**             | 0.815    |
| **mAP\@0.5:0.95**        | 0.663    |


Модель показывает высокую точность и хорошую обобщающую способность даже после короткого обучения (2 эпохи), благодаря начальной ручной аннотации и автолейблингу.

#### Качество по классам:

| Класс | Точность (P) | Полнота (R) | mAP\@0.5 | mAP\@0.5:0.95 |
| ----- | ------------ | ----------- | -------- | ------------- |
| cup   | 0.866        | 0.964       | 0.977    | 0.779         |
| soup  | 1.000        | 0.000       | 0.0001   | 0.00008       |
| meat  | 0.841        | 1.000       | 0.995    | 0.789         |
| salad | 0.912        | 0.908       | 0.949    | 0.666         |
| dish  | 0.971        | 0.987       | 0.994    | 0.931         |
| plate | 0.946        | 0.935       | 0.977    | 0.816         |


#### Выводы:

Качество детекции зависит от количества примеров в классе. Классы с малым числом примеров требуют доразметки или синтетического увеличения выборки.

Дальнейшее улучшение возможно при:

Увеличении числа размеченных изображений

Дополнительной аугментации редких классов

Увеличении числа эпох обучения


### Финальное разделение и структурирование датасета для YOLOv11

После объединения вручную размеченных и автоматически размеченных изображений был выполнен последний этап подготовки датасета — разделение на обучающую, валидационную и тестовую выборки, с сохранением совместимой структуры для обучения YOLOv11.

##### Источники:

1) Изображения: /extracted_frames — 680 изображений
2) Ручные разметки: /anno_labelimg — 180 аннотированных файлов
3) Авторазметки: /yolov8/labels_500_auto — 500 дополнительно размеченных изображений
4) Список классов: classes.txt — 8 классов

#### Основные этапы обработки:

1) Построение карты аннотаций
Создана ассоциативная структура label_map, связывающая имя изображения (без расширения) с его соответствующим .txt файлом из папки с ручной или автоматической разметкой.
2) Разделение на подмножества:
   2.1 Тестовая выборка (30% от ручной разметки): содержит только вручную размеченные изображения для честной оценки.
   2.2 Оставшиеся изображения случайным образом разбиты на:
      2.2.1 Тренировочную выборку (train) — 70%
      2.2.2 Валидационную выборку (val) — 20%


#### Копирование данных по структуре

```markdown
yolov11_dataset/
├── images/
│   ├── train/
│   ├── val/
│   └── test/
├── labels/
│   ├── train/
│   ├── val/
│   └── test/
├── classes.txt
└── dataset.yaml

```

### Аугментация тренировочного датасета

Для повышения обобщающей способности модели YOLOv11 была проведена аугментация изображений в тренировочной выборке. Использовалась библиотека Albumentations.

Входные данные:
1. Изображения: yolov11_dataset/images/train/
2. Аннотации: yolov11_dataset/labels/train/
3. YAML-файл: yolov11_dataset/dataset.yaml

# Финальный отчет по обучению YOLOv11

### Конфигурация обучения
1) Модель: YOLOv11s
2) Количество эпох: 2 (для быстрой итерации)
3) Размер изображения: 640x640
4) Платформа: CPU

Объем данных:
1) Тренировочных изображений: 1695 (включая аугментации)
2) Валидационных: 125
3) Тестовых: 54
4) Количество классов: 8


### Результаты базового обучения (до оптимизации)

| Метрика       | Значение |
| ------------- | -------- |
| **mAP50**     | 0.991    |
| **mAP50-95**  | 0.849    |
| **Precision** | 0.996    |
| **Recall**    | 0.991    |


Вывод: уже после 2 эпох модель показывает очень высокие значения точности и полноты. Это может быть связано с небольшим размером датасета и высокой качественной разметкой.


### Результаты оптимизации гиперпараметров

Было выполнено 2 итерации подбора:

#### Итерация 1
Параметры: lr0=0.01, batch=8, weight_decay=0.0005

mAP50-95: 0.859

#### Итерация 2
Параметры: lr0=0.01, batch=8, weight_decay=0.001

mAP50-95: 0.861 (лучшая)


Вывод: вторая итерация показала немного более высокие результаты


#### Результаты на тестовой выборке

| Метрика       | Значение |
| ------------- | -------- |
| **mAP50**     | 0.991    |
| **mAP50-95**  | 0.845    |
| **Precision** | 0.995    |
| **Recall**    | 0.984    |



#### Визуализация

Сгенерированы 5 предсказаний на тестовых изображениях. Сохранены в runs/train/test_results/.
Среднее количество предсказаний и средняя уверенность ~высокие.
Модель уверенно предсказывает границы объектов.


## Общие выводы
1) Даже при 2 эпохах обучения YOLOv11 показал высокую обобщающую способность.
2) Лучшие гиперпараметры найдены автоматически с помощью ParameterGrid.
3) Сильные стороны:Высокая точность предсказаний.
   3.1 Хорошая генерализация на тесте.
   3.2 Поддержка кастомного пайплайна через YOLOv11Trainer.
4)Улучшения в будущем:
   4.1 Добавить больше данных по недопредставленным классам (meat, soup).
   4.2 Увеличить количество эпох до 50+.
   4.3 Попробовать обучение на GPU для ускорения и большего батч-сайза.
   4.4 Провести полноценную кросс-валидацию.



























   
